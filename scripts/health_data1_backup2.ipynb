{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory set to: c:\\Users\\Dana\\Documents\\Kuliah\\Bangkit\\Capstone-C242-PS384_Project01\n",
      "\n",
      "Available files in directory:\n",
      "- anemia-dataset.csv\n",
      "- cholesterol-dataset.csv\n",
      "- chronic-kidney-disease-dataset.csv\n",
      "- diabetes-dataset.csv\n",
      "- health_data1_combined.csv\n",
      "- heart-disease-dataset.csv\n",
      "- hypertension-dataset.csv\n",
      "- metabolic-syndrome-dataset.csv\n",
      "- nafld1-dataset.csv\n",
      "- nafld2-dataset.csv\n",
      "- nwtco-dataset.csv\n",
      "- obesity-dataset.csv\n",
      "- stroke-dataset.csv\n",
      "\n",
      "Processing: anemia-dataset.csv\n",
      "Successfully loaded anemia-dataset.csv\n",
      "First few rows:\n",
      "   Gender  Hemoglobin   MCH  MCHC   MCV  Result\n",
      "0       1        14.9  22.7  29.1  83.7       0\n",
      "1       0        15.9  25.4  28.3  72.0       0\n",
      "2       0         9.0  21.5  29.6  71.2       1\n",
      "3       0        14.9  16.0  31.4  87.5       0\n",
      "4       1        14.7  22.0  28.2  99.5       0\n",
      "\n",
      "Processing: cholesterol-dataset.csv\n",
      "Successfully loaded cholesterol-dataset.csv\n",
      "First few rows:\n",
      "   age  sex  cp  trestbps  fbs  restecg  thalach  exang  oldpeak  slope ca  \\\n",
      "0   63    1   1       145    1        2      150      0      2.3      3  0   \n",
      "1   67    1   4       160    0        2      108      1      1.5      2  3   \n",
      "2   67    1   4       120    0        2      129      1      2.6      2  2   \n",
      "3   37    1   3       130    0        0      187      0      3.5      3  0   \n",
      "4   41    0   2       130    0        2      172      0      1.4      1  0   \n",
      "\n",
      "  thal  num  chol  \n",
      "0    6    0   233  \n",
      "1    3    2   286  \n",
      "2    7    1   229  \n",
      "3    3    0   250  \n",
      "4    3    0   204  \n",
      "\n",
      "Processing: chronic-kidney-disease-dataset.csv\n",
      "Successfully loaded chronic-kidney-disease-dataset.csv\n",
      "First few rows:\n",
      "   id   age    bp     sg   al   su     rbc        pc         pcc          ba  \\\n",
      "0   0  48.0  80.0  1.020  1.0  0.0     NaN    normal  notpresent  notpresent   \n",
      "1   1   7.0  50.0  1.020  4.0  0.0     NaN    normal  notpresent  notpresent   \n",
      "2   2  62.0  80.0  1.010  2.0  3.0  normal    normal  notpresent  notpresent   \n",
      "3   3  48.0  70.0  1.005  4.0  0.0  normal  abnormal     present  notpresent   \n",
      "4   4  51.0  80.0  1.010  2.0  0.0  normal    normal  notpresent  notpresent   \n",
      "\n",
      "   ...  pcv    wc   rc  htn   dm  cad appet   pe  ane classification  \n",
      "0  ...   44  7800  5.2  yes  yes   no  good   no   no            ckd  \n",
      "1  ...   38  6000  NaN   no   no   no  good   no   no            ckd  \n",
      "2  ...   31  7500  NaN   no  yes   no  poor   no  yes            ckd  \n",
      "3  ...   32  6700  3.9  yes   no   no  poor  yes  yes            ckd  \n",
      "4  ...   35  7300  4.6   no   no   no  good   no   no            ckd  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "\n",
      "Processing: diabetes-dataset.csv\n",
      "Successfully loaded diabetes-dataset.csv\n",
      "First few rows:\n",
      "    Age  Sex  HighChol  CholCheck   BMI  Smoker  HeartDiseaseorAttack  \\\n",
      "0   4.0  1.0       0.0        1.0  26.0     0.0                   0.0   \n",
      "1  12.0  1.0       1.0        1.0  26.0     1.0                   0.0   \n",
      "2  13.0  1.0       0.0        1.0  26.0     0.0                   0.0   \n",
      "3  11.0  1.0       1.0        1.0  28.0     1.0                   0.0   \n",
      "4   8.0  0.0       0.0        1.0  29.0     1.0                   0.0   \n",
      "\n",
      "   PhysActivity  Fruits  Veggies  HvyAlcoholConsump  GenHlth  MentHlth  \\\n",
      "0           1.0     0.0      1.0                0.0      3.0       5.0   \n",
      "1           0.0     1.0      0.0                0.0      3.0       0.0   \n",
      "2           1.0     1.0      1.0                0.0      1.0       0.0   \n",
      "3           1.0     1.0      1.0                0.0      3.0       0.0   \n",
      "4           1.0     1.0      1.0                0.0      2.0       0.0   \n",
      "\n",
      "   PhysHlth  DiffWalk  Stroke  HighBP  Diabetes  \n",
      "0      30.0       0.0     0.0     1.0       0.0  \n",
      "1       0.0       0.0     1.0     1.0       0.0  \n",
      "2      10.0       0.0     0.0     0.0       0.0  \n",
      "3       3.0       0.0     0.0     1.0       0.0  \n",
      "4       0.0       0.0     0.0     0.0       0.0  \n",
      "\n",
      "Processing: health_data1_combined.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dana\\AppData\\Local\\Temp\\ipykernel_37436\\3906519678.py:42: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded health_data1_combined.csv\n",
      "First few rows:\n",
      "  gender  hemoglobin  age  blood_pressure  cholesterol  glucose  bmi  height  \\\n",
      "0    1.0        14.9  NaN             NaN          NaN      NaN  NaN     NaN   \n",
      "1    0.0        15.9  NaN             NaN          NaN      NaN  NaN     NaN   \n",
      "2    0.0         9.0  NaN             NaN          NaN      NaN  NaN     NaN   \n",
      "3    0.0        14.9  NaN             NaN          NaN      NaN  NaN     NaN   \n",
      "4    1.0        14.7  NaN             NaN          NaN      NaN  NaN     NaN   \n",
      "\n",
      "   weight  HDL  Height  Weight  \n",
      "0     NaN  NaN     NaN     NaN  \n",
      "1     NaN  NaN     NaN     NaN  \n",
      "2     NaN  NaN     NaN     NaN  \n",
      "3     NaN  NaN     NaN     NaN  \n",
      "4     NaN  NaN     NaN     NaN  \n",
      "\n",
      "Processing: heart-disease-dataset.csv\n",
      "Successfully loaded heart-disease-dataset.csv\n",
      "First few rows:\n",
      "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
      "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
      "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
      "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
      "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
      "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
      "\n",
      "   ca  thal  target  \n",
      "0   2     3       0  \n",
      "1   0     3       0  \n",
      "2   0     3       0  \n",
      "3   1     3       0  \n",
      "4   3     2       0  \n",
      "\n",
      "Processing: hypertension-dataset.csv\n",
      "Successfully loaded hypertension-dataset.csv\n",
      "First few rows:\n",
      "    age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
      "0  57.0  1.0   3       145   233    1        0      150      0      2.3   \n",
      "1  64.0  0.0   2       130   250    0        1      187      0      3.5   \n",
      "2  52.0  1.0   1       130   204    0        0      172      0      1.4   \n",
      "3  56.0  0.0   1       120   236    0        1      178      0      0.8   \n",
      "4  66.0  0.0   0       120   354    0        1      163      1      0.6   \n",
      "\n",
      "   slope  ca  thal  target  \n",
      "0      0   0     1       1  \n",
      "1      0   0     2       1  \n",
      "2      2   0     2       1  \n",
      "3      2   0     2       1  \n",
      "4      2   0     2       1  \n",
      "\n",
      "Processing: metabolic-syndrome-dataset.csv\n",
      "Successfully loaded metabolic-syndrome-dataset.csv\n",
      "First few rows:\n",
      "    seqn  Age     Sex  Marital  Income   Race  WaistCirc   BMI  Albuminuria  \\\n",
      "0  62161   22    Male   Single  8200.0  White       81.0  23.3            0   \n",
      "1  62164   44  Female  Married  4500.0  White       80.1  23.2            0   \n",
      "2  62169   21    Male   Single   800.0  Asian       69.6  20.1            0   \n",
      "3  62172   43  Female   Single  2000.0  Black      120.4  33.3            0   \n",
      "4  62177   51    Male  Married     NaN  Asian       81.1  20.1            0   \n",
      "\n",
      "   UrAlbCr  UricAcid  BloodGlucose  HDL  Triglycerides  MetabolicSyndrome  \n",
      "0     3.88       4.9            92   41             84                  0  \n",
      "1     8.55       4.5            82   28             56                  0  \n",
      "2     5.07       5.4           107   43             78                  0  \n",
      "3     5.22       5.0           104   73            141                  0  \n",
      "4     8.13       5.0            95   43            126                  0  \n",
      "\n",
      "Processing: nafld1-dataset.csv\n",
      "Successfully loaded nafld1-dataset.csv\n",
      "First few rows:\n",
      "   Unnamed: 0  id  age  male  weight  height        bmi  case.id  futime  \\\n",
      "0        3631   1   57     0    60.0   163.0  22.690939  10630.0    6261   \n",
      "1        8458   2   67     0    70.4   168.0  24.884028  14817.0     624   \n",
      "2        6298   3   53     1   105.8   186.0  30.453537      3.0    1783   \n",
      "3       15398   4   56     1   109.3   170.0  37.830100   6628.0    3143   \n",
      "4       13261   5   68     1     NaN     NaN        NaN   1871.0    1836   \n",
      "\n",
      "   status  \n",
      "0       0  \n",
      "1       0  \n",
      "2       0  \n",
      "3       0  \n",
      "4       1  \n",
      "\n",
      "Processing: nafld2-dataset.csv\n",
      "Successfully loaded nafld2-dataset.csv\n",
      "First few rows:\n",
      "   Unnamed: 0  id  days  test  value\n",
      "0      135077   1  -459   hdl   75.0\n",
      "1      313143   1  -459  chol   75.0\n",
      "2      135078   1   183   hdl   64.0\n",
      "3      313144   1   183  chol   64.0\n",
      "4      135079   1  2030   hdl   74.0\n",
      "\n",
      "Processing: nwtco-dataset.csv\n",
      "Successfully loaded nwtco-dataset.csv\n",
      "First few rows:\n",
      "   Unnamed: 0  seqno  instit  histol  stage  study  rel  edrel  age  \\\n",
      "0           1      1       2       2      1      3    0   6075   25   \n",
      "1           2      2       1       1      2      3    0   4121   50   \n",
      "2           3      3       2       2      1      3    0   6069    9   \n",
      "3           4      4       2       1      4      3    0   6200   28   \n",
      "4           5      5       2       2      2      3    0   1244   55   \n",
      "\n",
      "   in.subcohort  \n",
      "0         False  \n",
      "1         False  \n",
      "2         False  \n",
      "3          True  \n",
      "4         False  \n",
      "\n",
      "Processing: obesity-dataset.csv\n",
      "Successfully loaded obesity-dataset.csv\n",
      "First few rows:\n",
      "   ID  Age  Gender  Height  Weight   BMI          Label\n",
      "0   1   25    Male     175      80  25.3  Normal Weight\n",
      "1   2   30  Female     160      60  22.5  Normal Weight\n",
      "2   3   35    Male     180      90  27.3     Overweight\n",
      "3   4   40  Female     150      50  20.0    Underweight\n",
      "4   5   45    Male     190     100  31.2          Obese\n",
      "\n",
      "Processing: stroke-dataset.csv\n",
      "Successfully loaded stroke-dataset.csv\n",
      "First few rows:\n",
      "   sex   age  hypertension  heart_disease  ever_married  work_type  \\\n",
      "0  1.0  63.0             0              1             1          4   \n",
      "1  1.0  42.0             0              1             1          4   \n",
      "2  0.0  61.0             0              0             1          4   \n",
      "3  1.0  41.0             1              0             1          3   \n",
      "4  1.0  85.0             0              0             1          4   \n",
      "\n",
      "   Residence_type  avg_glucose_level   bmi  smoking_status  stroke  \n",
      "0               1             228.69  36.6               1       1  \n",
      "1               0             105.92  32.5               0       1  \n",
      "2               1             171.23  34.4               1       1  \n",
      "3               0             174.12  24.0               0       1  \n",
      "4               1             186.21  29.0               1       1  \n",
      "Daftar file di dalam folder: ['anemia-dataset.csv', 'cholesterol-dataset.csv', 'chronic-kidney-disease-dataset.csv', 'diabetes-dataset.csv', 'health_data1_combined.csv', 'heart-disease-dataset.csv', 'hypertension-dataset.csv', 'metabolic-syndrome-dataset.csv', 'nafld1-dataset.csv', 'nafld2-dataset.csv', 'nwtco-dataset.csv', 'obesity-dataset.csv', 'stroke-dataset.csv']\n",
      "Semua file dataset ditemukan.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Step 0: Check if datasets exist\n",
    "\n",
    "def set_project_directory():\n",
    "    current_dir = os.getcwd()\n",
    "    \n",
    "    if os.path.basename(current_dir) == 'scripts':\n",
    "        os.chdir('..')\n",
    "    \n",
    "    print(f\"Working directory set to: {os.getcwd()}\")\n",
    "\n",
    "def calculate_bmi(weight, height):\n",
    "    if height > 0: # requirement tambahan biar data yang dimasukkan itu harus lebih dari 0\n",
    "        return weight / ((height / 100) ** 2)\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "def check_data_directory():\n",
    "    data_dir = os.path.join('dataset', 'health_data1')\n",
    "    if not os.path.exists(data_dir):\n",
    "        print(f\"Directory not found: {data_dir}\")\n",
    "        print(\"Available directories:\", os.listdir('.'))\n",
    "        return False\n",
    "    \n",
    "    print(\"\\nAvailable files in directory:\")\n",
    "    for file in os.listdir(data_dir):\n",
    "        print(f\"- {file}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "def load_data(file_path):\n",
    "    try:\n",
    "        if file_path.endswith('.csv'):\n",
    "            return pd.read_csv(file_path)\n",
    "        elif file_path.endswith('.XPT'):\n",
    "            return pd.read_sas(file_path)\n",
    "        else:\n",
    "            print(f\"Unsupported file format: {file_path}\")\n",
    "            return None\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "set_project_directory()\n",
    "\n",
    "if check_data_directory():\n",
    "    data_directory = os.path.join('dataset', 'health_data1')\n",
    "    \n",
    "    for filename in os.listdir(data_directory):\n",
    "        file_path = os.path.join(data_directory, filename)\n",
    "        print(f\"\\nProcessing: {filename}\")\n",
    "        data = load_data(file_path)\n",
    "        if data is not None:\n",
    "            print(f\"Successfully loaded {filename}\")\n",
    "            print(\"First few rows:\")\n",
    "            print(data.head())\n",
    "else:\n",
    "    print(\"Please check your directory structure and file locations\")\n",
    "\n",
    "folder_path = 'dataset/health_data1/'  # Ganti dengan jalur folder yang sesuai\n",
    "\n",
    "# Cek apakah folder dan file-file dataset ada\n",
    "try:\n",
    "    print(\"Daftar file di dalam folder:\", os.listdir(folder_path))\n",
    "    # List semua file yang diperlukan\n",
    "    required_files = [\n",
    "        'anemia-dataset.csv',\n",
    "        'cholesterol-dataset.csv',\n",
    "        'chronic-kidney-disease-dataset.csv',\n",
    "        'diabetes-dataset.csv',\n",
    "        'heart-disease-dataset.csv',\n",
    "        'hypertension-dataset.csv',\n",
    "        'metabolic-syndrome-dataset.csv',\n",
    "        'nafld1-dataset.csv',\n",
    "        'obesity-dataset.csv',\n",
    "        'stroke-dataset.csv'\n",
    "    ]\n",
    "    \n",
    "    # Cek keberadaan masing-masing file\n",
    "    missing_files = [f for f in required_files if not os.path.isfile(os.path.join(folder_path, f))]\n",
    "    \n",
    "    if missing_files:\n",
    "        print(f\"File yang hilang: {', '.join(missing_files)}\")\n",
    "    else:\n",
    "        print(\"Semua file dataset ditemukan.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Folder tidak ditemukan: {folder_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load all datasets\n",
    "datasets = {\n",
    "    \"anemia\": 'dataset/health_data1/anemia-dataset.csv',\n",
    "    \"cholesterol\": 'dataset/health_data1/cholesterol-dataset.csv',\n",
    "    \"kidney_disease\": 'dataset/health_data1/chronic-kidney-disease-dataset.csv',\n",
    "    \"diabetes\": 'dataset/health_data1/diabetes-dataset.csv',\n",
    "    \"heart_disease\": 'dataset/health_data1/heart-disease-dataset.csv',\n",
    "    \"hypertension\": 'dataset/health_data1/hypertension-dataset.csv',\n",
    "    \"metabolic_syndrome\": 'dataset/health_data1/metabolic-syndrome-dataset.csv',\n",
    "    \"nafld\": 'dataset/health_data1/nafld1-dataset.csv',\n",
    "    \"obesity\": 'dataset/health_data1/obesity-dataset.csv',\n",
    "    \"stroke\": 'dataset/health_data1/stroke-dataset.csv'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Calculate derived features based on user input\n",
    "def calculate_derived_features(user_input):\n",
    "    # Extract user input\n",
    "    height = user_input['height']\n",
    "    weight = user_input['weight']\n",
    "    age = user_input['age']\n",
    "    gender = user_input['gender']\n",
    "    blood_pressure = user_input['blood_pressure']\n",
    "    cholesterol = user_input['cholesterol']\n",
    "    blood_sugar = user_input['blood_sugar']\n",
    "\n",
    "    # Calculate derived features\n",
    "    bmi = weight / (height / 100) ** 2\n",
    "    sodium = weight * 20\n",
    "    if gender == 'Male':\n",
    "        fat = weight * 0.15\n",
    "    else:\n",
    "        fat = weight * 0.25\n",
    "    cholesterol_level = (bmi * 2) + (age * 0.15) + (blood_pressure * 0.05) + (blood_sugar * 0.02) + 150\n",
    "    protein = weight * 0.9\n",
    "    carbs = weight * 3\n",
    "\n",
    "    # Return calculated features as a dictionary\n",
    "    derived_features = {\n",
    "        'bmi': bmi,\n",
    "        'sodium': sodium,\n",
    "        'fat': fat,\n",
    "        'cholesterol': cholesterol_level,\n",
    "        'protein': protein,\n",
    "        'carbs': carbs\n",
    "    }\n",
    "    \n",
    "    return derived_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3\n",
    "def prepare_data_for_model(datasets):\n",
    "    features_list = []\n",
    "    target_list = []\n",
    "\n",
    "    for dataset_name, dataset in datasets.items():\n",
    "        # Load dataset\n",
    "        df = pd.read_csv(dataset)\n",
    "        \n",
    "        # Create temporary dataframe untuk fitur yang diperlukan\n",
    "        temp_df = pd.DataFrame()\n",
    "        \n",
    "        # Set target berdasarkan nama dataset\n",
    "        if dataset_name == \"stroke\":\n",
    "            target_col = 'stroke'\n",
    "        elif dataset_name == \"heart_disease\":\n",
    "            target_col = 'target'\n",
    "        elif dataset_name == \"diabetes\":\n",
    "            target_col = 'Diabetes'\n",
    "        elif dataset_name == \"kidney_disease\":\n",
    "            target_col = 'classification'\n",
    "        elif dataset_name == \"cholesterol\":\n",
    "            target_col = 'num'\n",
    "        elif dataset_name == \"anemia\":\n",
    "            target_col = 'Result'\n",
    "        elif dataset_name == \"hypertension\":\n",
    "            target_col = 'target'\n",
    "        elif dataset_name == \"metabolic_syndrome\":\n",
    "            target_col = 'MetabolicSyndrome'\n",
    "        elif dataset_name == \"nafld\":\n",
    "            target_col = 'status'\n",
    "        elif dataset_name == \"obesity\":\n",
    "            target_col = 'Label'\n",
    "            \n",
    "        # Pastikan kolom target ada\n",
    "        if target_col not in df.columns:\n",
    "            print(f\"Warning: {target_col} not found in {dataset_name}, skipping dataset\")\n",
    "            continue\n",
    "            \n",
    "        # Simpan nilai target\n",
    "        target = df[target_col]\n",
    "        \n",
    "        # Pilih dan standardisasi fitur\n",
    "        if 'age' in df.columns:\n",
    "            temp_df['age'] = df['age']\n",
    "        if 'gender' in df.columns or 'sex' in df.columns:\n",
    "            temp_df['gender'] = df['gender'] if 'gender' in df.columns else df['sex']\n",
    "        if 'bmi' in df.columns:\n",
    "            temp_df['bmi'] = df['bmi']\n",
    "        if 'blood_pressure' in df.columns or 'trestbps' in df.columns:\n",
    "            temp_df['blood_pressure'] = df['blood_pressure'] if 'blood_pressure' in df.columns else df['trestbps']\n",
    "        if 'cholesterol' in df.columns or 'chol' in df.columns:\n",
    "            temp_df['cholesterol'] = df['cholesterol'] if 'cholesterol' in df.columns else df['chol']\n",
    "            \n",
    "        # Hanya tambahkan dataset jika memiliki minimal 3 fitur yang tidak null\n",
    "        if temp_df.notna().sum(axis=1).mean() >= 3:\n",
    "            features_list.append(temp_df)\n",
    "            target_list.append(target)\n",
    "\n",
    "    # Gabungkan semua dataset\n",
    "    if not features_list:\n",
    "        raise ValueError(\"No valid datasets found\")\n",
    "        \n",
    "    features = pd.concat(features_list, ignore_index=True)\n",
    "    labels = pd.concat(target_list, ignore_index=True)\n",
    "    \n",
    "    # Handle missing values\n",
    "    features = features.fillna(features.mean())\n",
    "    \n",
    "    # Standardisasi fitur numerik\n",
    "    numeric_cols = ['age', 'bmi', 'blood_pressure', 'cholesterol']\n",
    "    for col in numeric_cols:\n",
    "        if col in features.columns:\n",
    "            features[col] = (features[col] - features[col].mean()) / features[col].std()\n",
    "    \n",
    "    # Konversi gender ke numeric\n",
    "    features['gender'] = features['gender'].map({'Male': 1, 'Female': 0, 'M': 1, 'F': 0, 1: 1, 0: 0})\n",
    "    features['gender'] = features['gender'].fillna(0)\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Train the model and save it to disk\n",
    "def train_and_save_model(data, labels, model_path='health_disease_predictor_model.pkl'):\n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.3, random_state=42)\n",
    "\n",
    "    # Initialize RandomForestClassifier\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Test the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Save the model to disk\n",
    "    joblib.dump(model, model_path)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dana\\Documents\\Kuliah\\Bangkit\\Capstone-C242-PS384_Project01\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dana\\Documents\\Kuliah\\Bangkit\\Capstone-C242-PS384_Project01\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Dana\\Documents\\Kuliah\\Bangkit\\Capstone-C242-PS384_Project01\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      3762\n",
      "           1       0.96      0.97      0.97      4441\n",
      "           2       0.00      0.00      0.00         9\n",
      "           3       0.00      0.00      0.00         9\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.96      8224\n",
      "   macro avg       0.38      0.38      0.38      8224\n",
      "weighted avg       0.96      0.96      0.96      8224\n",
      "\n",
      "Model saved to health_disease_predictor_model.pkl\n",
      "Model loaded from health_disease_predictor_model.pkl\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- bmi\n- carbs\n- fat\n- protein\n- sodium\nFeature names seen at fit time, yet now missing:\n- age\n- blood_pressure\n- gender\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m train_and_save_model(data, labels)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Predict disease risk for a new user\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_disease_risk\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted disease risk:\u001b[39m\u001b[38;5;124m\"\u001b[39m, prediction)\n",
      "Cell \u001b[1;32mIn[13], line 14\u001b[0m, in \u001b[0;36mpredict_disease_risk\u001b[1;34m(user_input, model_path)\u001b[0m\n\u001b[0;32m     11\u001b[0m user_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([derived_features])\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Predict the disease risk\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prediction\n",
      "File \u001b[1;32mc:\\Users\\Dana\\Documents\\Kuliah\\Bangkit\\Capstone-C242-PS384_Project01\\.venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:823\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    803\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    805\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 823\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    825\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    826\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Dana\\Documents\\Kuliah\\Bangkit\\Capstone-C242-PS384_Project01\\.venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:865\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    863\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    864\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[1;32m--> 865\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    868\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32mc:\\Users\\Dana\\Documents\\Kuliah\\Bangkit\\Capstone-C242-PS384_Project01\\.venv\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:599\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    598\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 599\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[0;32m    601\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Dana\\Documents\\Kuliah\\Bangkit\\Capstone-C242-PS384_Project01\\.venv\\lib\\site-packages\\sklearn\\base.py:580\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    511\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    517\u001b[0m ):\n\u001b[0;32m    518\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    519\u001b[0m \n\u001b[0;32m    520\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    579\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 580\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    582\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    583\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    584\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    585\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    586\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Dana\\Documents\\Kuliah\\Bangkit\\Capstone-C242-PS384_Project01\\.venv\\lib\\site-packages\\sklearn\\base.py:507\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    503\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n\u001b[1;32m--> 507\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- bmi\n- carbs\n- fat\n- protein\n- sodium\nFeature names seen at fit time, yet now missing:\n- age\n- blood_pressure\n- gender\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Load model and predict disease risk for a new user\n",
    "def predict_disease_risk(user_input, model_path='health_disease_predictor_model.pkl'):\n",
    "    # Load the saved model\n",
    "    model = joblib.load(model_path)\n",
    "    print(f\"Model loaded from {model_path}\")\n",
    "    \n",
    "    # Calculate derived features for user\n",
    "    derived_features = calculate_derived_features(user_input)\n",
    "    \n",
    "    # Create a dataframe for the model input\n",
    "    user_data = pd.DataFrame([derived_features])\n",
    "    \n",
    "    # Predict the disease risk\n",
    "    prediction = model.predict(user_data)\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "\n",
    "# Example of user input\n",
    "user_input = {\n",
    "    'height': 170,  # in cm\n",
    "    'weight': 70,  # in kg\n",
    "    'age': 30,\n",
    "    'gender': 'Male',\n",
    "    'blood_pressure': 120,\n",
    "    'cholesterol': 200,\n",
    "    'blood_sugar': 90\n",
    "}\n",
    "\n",
    "# Prepare the data for model training\n",
    "data, labels = prepare_data_for_model(datasets)\n",
    "\n",
    "# Train and save the model\n",
    "train_and_save_model(data, labels)\n",
    "\n",
    "# Predict disease risk for a new user\n",
    "prediction = predict_disease_risk(user_input)\n",
    "print(\"Predicted disease risk:\", prediction)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
